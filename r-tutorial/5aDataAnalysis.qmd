---
title: "Regression Analysis and ARIMA Time Series Forecasting with R"
author: "Mohan Khanal"
date: "2025-08-06"
format:
  html:
    toc: true
    toc-location: left
    toc-title: "Contents"
    toc-depth: 2
  pdf:
    toc: true
    number-sections: true
---

# Regression Analysis and ARIMA Time Series Forecasting with R

```{r}
# Load Required Libraries
library(dplyr)
library(ggplot2)
library(stats)    # For lm(), glm(), and arima()
library(datasets) # For mtcars, AirPassengers
library(forecast) # For ARIMA modeling
library(ISLR)     # For Credit dataset
```



## Part 1: Linear Regression
Understanding: Linear regression models the relationship between a continuous dependent variable and one or more predictors (continuous or categorical).
Dataset: We use the mtcars dataset, which contains car attributes like miles per gallon (mpg), horsepower (hp), weight (wt), and transmission type (am: 0 = automatic, 1 = manual).
Example: Predict mpg using hp, wt, and am.



```{r}
# Preview data
head(mtcars)

# Fit linear regression model
lin_reg <- lm(mpg ~ hp + wt + am, data = mtcars)
summary(lin_reg)
```


Interpretation:

Coefficients: Each predictorâ€™s coefficient indicates the change in mpg per unit change in the predictor, holding others constant.
Positive coefficient: As predictor increases, mpg increases.
Negative coefficient: As predictor increases, mpg decreases.
p-value < 0.05 for a coefficient: Predictor has a statistically significant effect on mpg.
R-squared: Proportion of variance in mpg explained by the model (higher is better, max = 1).
Adjusted R-squared: Accounts for the number of predictors; use for model comparison.

## Part 2: Logistic Regression
Understanding: Logistic regression models the probability of a binary outcome based on one or more predictors.
Dataset: We use the Credit dataset from the ISLR package, which contains credit card data including Income, Balance, Age, and Married status (Yes/No). We create a binary target marriedTarget (1 = Yes, 0 = No).
Example: Predict Married status using Income, Balance, and Age.

```{r}
# Load and prepare Credit dataset
data(Credit)
credit_data <- Credit
credit_data$marriedTarget <- ifelse(credit_data$Married == "Yes", 1, 0)

# Preview data
head(credit_data)

# Fit logistic regression model
log_reg <- glm(marriedTarget ~ Income + Balance + Age, family = binomial(link = "logit"), data = credit_data)
summary(log_reg)
```

Interpretation:
Coefficients: Represent the change in the log-odds of Married = Yes per unit change in the predictor.
Positive coefficient: Predictor increases the probability of being married.
Increase in Income increases the probability of being married. 
The log-odds of married person to income is 0.004 

Negative coefficient: Predictor decreases the probability of being married.
p-value < 0.05 for a coefficient: Predictor significantly affects the probability of being married.
Deviance: Lower residual deviance indicates a better fit.
AIC: Lower values indicate a better model fit, useful for model comparison.

## Part 3: ARIMA Time Series Forecasting
Understanding: ARIMA (AutoRegressive Integrated Moving Average) models time series data to forecast future values based on past patterns.
Dataset: We use the AirPassengers dataset, a monthly time series of airline passenger counts from 1949 to 1960.
Example: Forecast passenger counts for the next 12 months.
# Preview data

```{r}
plot(AirPassengers, main = "Monthly Airline Passengers (1949-1960)", ylab = "Passengers", xlab = "Year")

# Fit ARIMA model (auto.arima selects optimal parameters)
arima_model <- forecast::auto.arima(AirPassengers)
summary(arima_model)

# Forecast next 12 months
arima_forecast <- forecast::forecast(arima_model, h = 12)

# Plot forecast
plot(arima_forecast, main = "ARIMA Forecast for AirPassengers", ylab = "Passengers", xlab = "Year")
```


Interpretation:

ARIMA(p,d,q):
p: Number of autoregressive terms (lagged observations).
d: Number of differences to make the series stationary.
q: Number of moving average terms (lagged forecast errors).


Coefficients: Significant if p-value < 0.05.
AIC/BIC: Lower values indicate a better model fit.
Forecast Plot: Shows predicted values with confidence intervals (e.g., 80% and 95% intervals).

## Part 4: Visualizations----
```{r}
# Linear regression: Scatter plot with regression line
ggplot(mtcars, aes(x = wt, y = mpg, color = as.factor(am))) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "MPG vs Weight by Transmission", x = "Weight (1000 lbs)", y = "MPG", color = "Transmission (0=Auto, 1=Manual)") +
  theme_minimal()

# Logistic regression: Predicted probabilities
credit_data$pred_prob <- predict(log_reg, type = "response")
ggplot(credit_data, aes(x = Age, y = pred_prob, color = Gender)) +
  geom_point(alpha = 0.5) +
  labs(title = "Predicted Probability of Being Married by Age and Gender", x = "Age", y = "Probability of Being Married") +
  theme_minimal()
```



## Part 5: Practice Tasks

Fit a linear regression model to predict disp (displacement) in mtcars using hp, wt, and cyl. Interpret the coefficients and R-squared.
Fit a logistic regression model to predict marriedTarget in credit_data using only Income and Age. Compare the AIC with the model in Part 2.
Fit an ARIMA model to the Nile dataset (annual Nile river flow). Forecast the next 5 years and plot the results.
Create a ggplot2 visualization for the linear regression model in Task 1, showing disp vs. wt with a regression line, colored by cyl.

## Feedback
This tutorial demonstrates:

How to perform linear and logistic regression in R.
How to model and forecast time series data using ARIMA.
How to interpret model outputs (coefficients, p-values, R-squared, AIC, etc.).
How to visualize regression and forecasting results.


